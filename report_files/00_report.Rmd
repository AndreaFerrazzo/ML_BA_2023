---
title: "Recipe Rating Analysis: Nutritional Values and Ingredients"
author: "Andrea Ferrazzo, Jordan Vazquez"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  rmdformats::readthedown:
    code_folding: hide
    highlight: espresso
    self_contained: true
    toc_depth: 3
    number_sections: true
---

```{css, echo = FALSE}
#sidebar {
  background: #5A7B9C;
}

#postamble {
  background:#003366;
  border-top:solid 10px #5A7B9C;
}

.title {
  text-align: center;
  color: #003366;
}

.subtitle {
  color: #003366;
}

h1, h2, h3, h4, h5, h6, legend {
  color: #5A7B9C;
}

#sidebar h2 {
    background-color: #003366;
}
#sidebar a {
    color: #003366;
}
#sidebar a:hover {
    color: #FFFFFF;
}
```

```{r child = c('setup.Rmd', '01_data.Rmd', '02_eda.Rmd')}

``` 

```{r}
#'03_supervised_learning.Rmd', '04_unsupervised_learning.Rmd'
```



Questions
- should we convert the binary columns to factor or can we leave them as integer for modelling?
- should we balance the data, in the rating_bin case and in the rating normal with 7 classes
- should we normalise the numerical data
- it's mentionned in the slides that the validation set should not be balanced, but how do we do that using train() with caret?
- should we really used balanced data for training? Because at least for KNN it always makes K=1 better, whereas K is was larger when we trained with unbalanced data
  Apparently for KNN, it's not required to balance data


